# LLM Development Skills Tracker

## Core Skills & Weightings

### 1. API integration + prompt engineering (25%)
- **Description:** Ability to integrate with LLM APIs (OpenAI, Anthropic, etc.) and craft effective prompts
- **Key concepts:** API authentication, request/response handling, prompt structure, few-shot learning, temperature/top-p tuning
- **Tools:** OpenAI SDK, Anthropic SDK, custom prompt templates

### 2. RAG fundamentals (embedding, vector DBs, retrieval pipelines) (20%)
- **Description:** Understanding and implementing Retrieval-Augmented Generation systems
- **Key concepts:** Embeddings, vector similarity, chunking strategies, retrieval methods, context window management
- **Tools:** OpenAI embeddings, Pinecone, Weaviate, Chroma, sentence-transformers

### 3. Tooling fluency: LangChain, LlamaIndex, etc. (15%)
- **Description:** Proficiency with modern LLM development frameworks
- **Key concepts:** Chain composition, memory management, tool integration, streaming responses
- **Tools:** LangChain, LlamaIndex, Semantic Kernel, AutoGen

### 4. Full-stack integration: FastAPI, Streamlit, minimal frontend (10%)
- **Description:** Building complete applications that integrate LLM capabilities
- **Key concepts:** API design, state management, real-time updates, deployment considerations
- **Tools:** FastAPI, Streamlit, React/Vue.js basics, Docker

### 5. Evaluation mindset: test outputs, sanity checks, error handling (10%)
- **Description:** Systematic approach to testing and validating LLM outputs
- **Key concepts:** Output validation, A/B testing, error recovery, performance monitoring
- **Tools:** Custom evaluation scripts, LangSmith, Promptfoo, logging frameworks

### 6. Open-source model familiarity: Ollama, GGUF, Hugging Face (8%)
- **Description:** Working with local and open-source LLM models
- **Key concepts:** Model quantization, local inference, model comparison, fine-tuning basics
- **Tools:** Ollama, Hugging Face Transformers, GGUF models, LoRA

### 7. Model literacy: context windows, token limits, generation parameters (7%)
- **Description:** Deep understanding of how LLM models work and their limitations
- **Key concepts:** Tokenization, context windows, attention mechanisms, generation strategies
- **Tools:** Tokenizers, model documentation, performance analysis

### 8. AI safety, output filtering, ethical design considerations (5%)
- **Description:** Building responsible and safe LLM applications
- **Key concepts:** Content filtering, bias detection, hallucination prevention, ethical guidelines
- **Tools:** OpenAI moderation API, custom filters, safety evaluation frameworks

## Project Tracking Structure

Each project should have its own tracking file that documents:
- How each skill was used in the project
- What was learned about each skill
- Plans for deeper integration in future iterations
- Challenges encountered and solutions found

## Learning Approach

**Non-linear skill development:** Focus on projects first, then weave in skills as needed. Each project should touch multiple skills at different levels of depth. 